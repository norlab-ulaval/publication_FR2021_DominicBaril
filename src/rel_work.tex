\section{Related work}
\label{sec:rel_work}

\subsection{Robotic deployments in snow}
\label{sec:snow_robots}

\begin{figure}[thbp]
  \centering
  \input{figs/RW_graph/RW_graph.tikz}
  \caption{graph of RW robotics deployements}
  \label{fig:RW_graph}
\end{figure}

To our knowledge, few robots have been deployed in harsh winter environments. 
Dante II is a \SI{900}{kg} tethered legged robot, which conducted a 5-day, \SI{165}{m} descent into the Mount Spurr Volcano, in Alaska~\citep{Bares1999}.
During this deployment, Dante II reached speeds upwards to \SI{0.011}{m/s} during the descent.
A two-axis lidar was used to create a local elevation map around the robot in order to conduct autonomous navigation.

Nomad is a gasoline-powered \SI{725}{kg} \ac{UGV}, was deployed at Elephant Moraine, Antarctica for a duration of 4 weeks~\citep{Apostolopoulos2000}. 
The robot reached speeds upwards of \SI{0.5}{m/s} while using differential-\ac{GPS} as the primary method of localization.
The platform also used stereo cameras and a lidar sensor for obstacle detection, although stereo vision was found to be ineffective  on blue ice and snow in Antarctica due to extreme lack of texture~\citep{Moorehead1999}.
Roll/pitch/yaw sensors were also added to the robot to make it cognizant to hazardous terrain.
Nomad achieved its initial goal to identify meteorites autonomously in Antarctica at a search rate of~\SI{160}{m^2/h}. %JL: removed extra space between and after ~

MARVIN I and MARVIN II are two diesel-powered \acp{SSMR} weighing \SI{720}{kg} were deployed in Greenland~\citep{Stansbury2004} and Antarctica~\citep{Gifford2009} respectively. 
The goal of these robots was to increase survey safety in remote polar regions and large sensor payloads led to the selection of large vehicles.
Both vehicles used \ac{RTK} \ac{GPS} as primary method, achieving a centimeter-level accuracy.
They also used a lidar sensor for obstacle detection and a gyroscope and inclinometer were used to provide the robot's pitch and roll angles.
Skid-steer turns often caused MARVIN I to get immobilized in snow and its transmission eventually broke down during operation.
MARVIN II thus incorporated design improvements to the hydro-static drive and track systems to increase its durability.


Sno-mote Mk1 and Mk2 are dual-drive 1:10 scale snowmobiles equipped with a single camera and \ac{GPS} antenna were deployed on Alaskan glaciers and Wapekoneta, Ohio~\citep{Williams2009}.
These robots were used to conduct manually-driven traverses of about \SI{100}{m} at a speed of ~\SI{1}{m/s}.
The data gathered with the Sno-motes was then used to improve visual \ac{SLAM} feature extraction methods in snow. 
Despite improving feature detection methods on snow, it was shown that snow is still feature-sparse~\citep{Williams2009}.
Through this work, improvements were also done on slope estimation~\citep{Williams2010} and horizon line estimation~\citep{Williams2011}.

Yeti is a battery-powered \SI{81}{kg} \ac{UGV} in Antarctica and Greenland~\citep{Lever2013}. 
Yeti was used to conduct \ac{GPR} surveys in order to detect subsurface crevasses or other voids to increase vehicle travel safety in remote polar environments.
Since polar terrain is largely obstacle-free and the effort required to provide reliable obstacle detection on low-contrast snowfields is considerable, Yeti drove "blind", relying only on \ac{GPS} waypoint following.
During surveys, Yeti reached a top speed of \SI{2.2}{m/s} and managed to acquire data on hundreds of crevasse encounters and even locate a previously undetected buried building in the South Pole.

A Clearpath Robotics Grizzly, a battery- and gasoline-powered \ac{SSMR} was deployed during winter on the University of Toronto Institute for Aerospace Studies (UTIAS) campus, in Ontario, Canada~\citep{Paton2017}.
Only stereo cameras were used through a visual \ac{SLAM} algorithm to localize the robot during autonomous teach-and-repeat runs. 
Path tracking was accomplished using a \ac{MPC} algorithm.
A 250 m path was successfully repeated on a light snow cover 3 hours after it was first manually driven. 
However, deep snow path-following provided unsatisfactory results due to features almost only being observed on the horizon, leading to inaccurate pose estimates, which caused issues for the path tracker.
Furthermore, vehicle tracks that constantly change when driven over lead to an increased pose estimation error.

A full-scale battery-powered Toyota Prius was deployed during winter on roads in Massachusetts, USA~\citep{Ort2020}.
Localization was accomplished using a custom-designed localizing \ac{GPR}. 
A prior mapping must be conducted during which the driven is driven by a human operator and the vehicle's sensor data is recorded, the saved map can then allow the vehicle to localize within this area.
The \ac{GPR} location information is then probabilistically fused with wheel odometry and \ac{IMU} measurements to provide accurate vehicle localization.
Path tracking is accomplished through the use of a Pure Pursuit controller, specifically designed for Ackermann steered autonomous vehicles.
The system showed similar performance in localization accuracy (\SI{0.34}{m} to \SI{0.39}{m}) and cross-track error (\SI{0.26}{m} to \SI{0.29}{m}) between clear weather and snow-covered road.
The localizing \ac{GPR} sensor's measurement range depends on the width of the array, meaning the system cannot be easily miniaturized, which means it was mounted on the rear of the vehicle, at \SI{32}{cm} above the ground.
This sensor size and mounting requirement could lead to decreased performance in deep snow or in off-road environments. 

In this work, we demonstrate that lidar-based localization and navigation allows a robot to localize in \ac{GNSS}-deprived areas as well in snow-covered terrain.
Our system has been deployed in complex meteorological scenarios, relying on lidar, \ac{IMU} and wheel encoders measurements to localize and track the desired path through a week-long deployment in a subarctic forest. 

%JL: I think the section misses connections between the papers, maybe a figure would help? (x: max speed, y: max snow depth, place the papers in this graph, for instance)

\subsection{Teach-and-Repeat}
\label{rel_nav}

% Text on topological path tracking / SLAM?

In \ac{VTR}, a robot is first driven manually along a given path as a training example in order to build a manifold map of overlapping submaps. 
Then, a visual path-tracking system is able to achieve high autonomy rates over many kilometers of steep terrain, relying on a single stereo camera~\citep{Furgale2010}. %JL: changed km to its US variant
\ac{EBN} has then been introduced to increase the robustness of \ac{VTR} to scene appearance change, caused by illumination variation or dynamic environment changes~\citep{Churchill2013}. 
This feature was added in \ac{VTR} through \ac{MEL}, with the added ability to use landmarks from previous experiences in the same localization problem~\citep{Paton2016}.
Recall of relevant landmarks for a specific scenario was then improved in computation speed through a bag-of-word approach~\citep{MacTavish2017}.
To mitigate the impact of illumination variations, color-constant image transformations have been added to \ac{VTR}~\citep{Paton2015}. %JL: changed colour to color (UK/US)/
The \ac{VTR} framework has also been shown to work with various sensors, such as intensity-based lidar~\citep{McManus2013} and monocular cameras~\citep{Clement2017}.
\acp{CNN} and particle filters have also been used for visual place recognition in \ac{VTR} frameworks in order to localize the robot in the taught trajectory~\citep{Camara2020}.
In this work, the horizontal offset of the reference image with the current image is used to correct the steering during the teach phase.
Recently,~\citet{Congram2021} expanded \ac{VTR}'s localization ability to environments where the ability to visually localize is compromised by using \ac{GNSS} measurements.
While \ac{VTR} has proven to be an efficient method for repeating trajectories in outdoor environments, the literature does not show the system to be deployed in snow.
Our work aims to demonstrate that \ac{LTR} approaches allow repeating trajectories that were recorded multiple days prior and under vastly different lighting conditions. %JL: allow X to ... or allow verb+ing
We also demonstrate that \ac{LTR} offers good performance on snow-covered terrain, which is known to be complex for visual localization.

% Add quadcopter papers?

While all these works rely on using cameras, \ac{LTR} is a similar framework relying on lidar sensors.
\citet{Marshall2008} were the first to suggest a similar framework using encoders and 2D lidars.
In this work, a sequence of overlapping metric maps are recorded along the path using 2D lidar measurements to allow the robot to localize within during the repeat phase.
\citet{Sprunk2013} used a similar approach to \ac{LTR}, however the teach phase directly logs 2D lidar data at an interval based on the distance from the last recorded scan.
\citet{Mazuran2015} have improved this framework by introducing an optimization step between the teach and the repeat phase, allowing the constraints to be defined by user preferences.
While more focused on localization,~\citet{Landry2016} have worked to improve topometric maps used to localize the robot during the repeat phase in order to minimize the number of nodes in the topometric map.
In this work, the localization was done using a 3D lidar. 
Following a similar idea, \citet{Boniardi2017} have extended this work to allow using architectural floor plans of buildings to localize within using 2D lidar scans.
Our work differs from previous work on \ac{LTR} mainly because the system is deployed in an unstructured, outdoor environment and subject to harsh winter conditions. 
We also demonstrate the performance of our \ac{LTR} system on \SI{22}{km} of autonomous path repeating.

%% Sentence about 3D lidar TnR

\begin{figure} [htpb]
	\centering
	\includegraphics[height=3.0in]{example-image}
	\caption{Related deployments}
	\label{fig:rel_work}
\end{figure}


% Paragraph on ICP and large scale outdoor localization using lidars?



